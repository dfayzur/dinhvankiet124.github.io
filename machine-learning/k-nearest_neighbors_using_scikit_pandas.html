v<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="Notes on Data Science, Machine Learning, &amp; Artificial Intelligence">
    <meta name="author" content="Chris Albon">
    <link rel="icon" href="../favicon.ico">

    <title>K-Nearest Neighbors Classification - Machine Learning</title>

    <!-- JQuery -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>
        window.jQuery || document.write('<script src="../theme/js/jquery.min.js"><\/script>')
    </script>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="../theme/css/bootstrap.css" />
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link rel="stylesheet" type="text/css" href="../theme/css/ie10-viewport-bug-workaround.css" />
    <!-- Custom styles for this template -->
    <link rel="stylesheet" type="text/css" href="../theme/css/style.css" />
    <link rel="stylesheet" type="text/css" href="../theme/css/notebooks.css" />
    <link href='https://fonts.googleapis.com/css?family=PT+Serif:400,700|Roboto:400,500,700' rel='stylesheet' type='text/css'>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
     <link href="http://chrisalbon.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Machine Learning and Artificial Intelligence Full RSS Feed" />         <link href="http://chrisalbon.com/feeds/machine-learning.rss.xml" type="application/rss+xml" rel="alternate" title="Machine Learning and Artificial Intelligence Categories RSS Feed" />    

    <meta name="tags" content="Nearest Neighbors" />

    <meta name="google-site-verification" content="7RLmddm4HbzdQLpwH2LH94_vBNmcaMGZSEhmmF5n0NM" />
</head>

<body>

    <div class="navbar navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="..">Chris Albon</a>
            </div>
            <div class="navbar-collapse collapse" id="searchbar">

                <ul class="nav navbar-nav navbar-right">
                  <li class="dropdown">
                      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">ML/AI Notes<span class="caret"></span></a>
                      <ul class="dropdown-menu">
                          <li><a href="..#Blog">Blog</a></li>
                          <li><a href="..#Machine-Learning">Machine Learning</a></li>
                          <li><a href="..#Deep-Learning">Deep Learning</a></li>
                          <li><a href="..#Algorithms">Algorithms</a></li>
                          <li><a href="..#Python">Python</a></li>
                          <li><a href="..#Statistics">Statistics</a></li>
                          <li><a href="..#Cloud-Computing">Cloud Computing</a></li>
                          <li><a href="..#Javascript">Javascript</a></li>
                          <li><a href="..#SQL">SQL</a></li>
                          <li><a href="..#Scala">Scala</a></li>
                          <li><a href="..#Regex">Regex</a></li>
                          <li><a href="..#Mathematics">Mathematics</a></li>
                      </ul>
                  </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">About<span class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a href="../pages/about.html">About Chris</a></li>
                            <li><a href="https://github.com/chrisalbon">GitHub</a></li>
                            <li><a href="https://twitter.com/chrisalbon">Twitter</a></li>
                            <li><a href="https://www.linkedin.com/in/chrisralbon">LinkedIn</a></li>
                            <li><a href="https://pinboard.in/u:chrisalbon">Pinboard</a></li>
                        </ul>
                    </li>


                    <!--<li class="dropdown">
                        <a href="../feeds/blog.rss.xml">Blog RSS</a>
                    </li>-->


                </ul>

                <form class="navbar-form" action="../search.html" onsubmit="return validateForm(this.elements['q'].value);">
                    <div class="form-group" style="display:inline;">
                        <div class="input-group" style="display:table;">
                            <span class="input-group-addon" style="width:1%;"><span class="glyphicon glyphicon-search"></span></span>
                            <input class="form-control search-query" name="q" id="tipue_search_input" placeholder="e.g. scikit KNN, pandas merge" required autocomplete="off" type="text">
                        </div>
                    </div>
                </form>

            </div>
            <!--/.nav-collapse -->
        </div>
    </div>



    <!-- end of header section -->
    <div class="container">
<div class="alert alert-warning advert" role="alert">
    Want to learn machine learning? Use my <a href="https://machinelearningflashcards.com" class="alert-link">machine learning flashcards</a>.
</div>

<section id="content" class="body">
    <header>
    <h1>
      K-Nearest Neighbors Classification
    </h1>
<ol class="breadcrumb">
    <li>
        <time class="published" datetime="2016-08-31T12:00:00-07:00">
            31 August 2016
        </time>
    </li>
    <li>Machine Learning</li>
    <li>Nearest Neighbors</li>
</ol>
</header>
<div class='article_content'>
<p>K-nearest neighbors classifier (KNN) is a simple and powerful classification learner. </p>
<p>KNN has three basic parts:</p>
<ul>
<li>$y_i$: The class of an observation (what we are trying to predict in the test data).</li>
<li>$X_i$: The predictors/IVs/attributes of an observation.</li>
<li>$K$: A positive number specified by the researcher. K denotes the number of observations closest to a particular observation that define its "neighborhood". For example, K=2 means that each observation's has a neighorhood comprising of the two other observations closest to it.</li>
</ul>
<p>Imagine we have an observation where we know its independent variables $x_{test}$ but do not know its class $y_{test}$. The KNN learner finds the K other observations that are closest to $x_{test}$ and uses their known classes to assign a classes to $x_{test}$.</p>
<h2>Preliminaries</h2>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>  
<span class="kn">import</span> <span class="nn">seaborn</span>
</pre></div>


<h2>Create Dataset</h2>
<p>Here we create three variables, <code>test_1</code> and <code>test_2</code> are our independent variables, 'outcome' is our dependent variable. We will use this data to train our learner.</p>
<div class="highlight"><pre><span></span><span class="n">training_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

<span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;test_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3051</span><span class="p">,</span><span class="mf">0.4949</span><span class="p">,</span><span class="mf">0.6974</span><span class="p">,</span><span class="mf">0.3769</span><span class="p">,</span><span class="mf">0.2231</span><span class="p">,</span><span class="mf">0.341</span><span class="p">,</span><span class="mf">0.4436</span><span class="p">,</span><span class="mf">0.5897</span><span class="p">,</span><span class="mf">0.6308</span><span class="p">,</span><span class="mf">0.5</span><span class="p">]</span>
<span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;test_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5846</span><span class="p">,</span><span class="mf">0.2654</span><span class="p">,</span><span class="mf">0.2615</span><span class="p">,</span><span class="mf">0.4538</span><span class="p">,</span><span class="mf">0.4615</span><span class="p">,</span><span class="mf">0.8308</span><span class="p">,</span><span class="mf">0.4962</span><span class="p">,</span><span class="mf">0.3269</span><span class="p">,</span><span class="mf">0.5346</span><span class="p">,</span><span class="mf">0.6731</span><span class="p">]</span>
<span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;outcome&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;win&#39;</span><span class="p">,</span><span class="s1">&#39;win&#39;</span><span class="p">,</span><span class="s1">&#39;win&#39;</span><span class="p">,</span><span class="s1">&#39;win&#39;</span><span class="p">,</span><span class="s1">&#39;win&#39;</span><span class="p">,</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>

<span class="n">training_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>test_1</th>
      <th>test_2</th>
      <th>outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.3051</td>
      <td>0.5846</td>
      <td>win</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.4949</td>
      <td>0.2654</td>
      <td>win</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.6974</td>
      <td>0.2615</td>
      <td>win</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.3769</td>
      <td>0.4538</td>
      <td>win</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.2231</td>
      <td>0.4615</td>
      <td>win</td>
    </tr>
  </tbody>
</table>
</div>

<h2>Plot the data</h2>
<p>This is not necessary, but because we only have three variables, we can plot the training dataset. The X and Y axes are the independent variables, while the colors of the points are their classes.</p>
<div class="highlight"><pre><span></span><span class="n">seaborn</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="s1">&#39;test_1&#39;</span><span class="p">,</span> <span class="s1">&#39;test_2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">training_data</span><span class="p">,</span> <span class="n">fit_reg</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s2">&quot;outcome&quot;</span><span class="p">,</span> <span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;D&quot;</span><span class="p">,</span><span class="s2">&quot;s&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">})</span>
</pre></div>


<div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.FacetGrid at 0x11008aeb8&gt;
</pre></div>


<p><img alt="png" src="k-nearest_neighbors_classifer_files/k-nearest_neighbors_classifer_9_1.png"></p>
<h2>Convert Data Into np.arrays</h2>
<p>The <code>scikit-learn</code> library requires the data be formatted as a <code>numpy</code> array. Here are doing that reformatting.</p>
<div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">training_data</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;test_1&#39;</span><span class="p">,</span> <span class="s1">&#39;test_2&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;outcome&#39;</span><span class="p">])</span>
</pre></div>


<h2>Train The Learner</h2>
<p>This is our big moment. We train a KNN learner using the parameters that an observation's neighborhood is its three closest neighors. <code>weights = 'uniform'</code> can be thought of as the voting system used. For example, <code>uniform</code> means that all neighbors get an equally weighted "vote" about an observation's class while <code>weights = 'distance'</code> would tell the learner to weigh each observation's "vote" by its distance from the observation we are classifying. </p>
<div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span><span class="p">)</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>


<h2>View The Model's Score</h2>
<p>How good is our trained model compared to our training data?</p>
<div class="highlight"><pre><span></span><span class="n">trained_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>0.80000000000000004
</pre></div>


<p>Our model is 80% accurate! </p>
<p><em>Note: that in any real world example we'd want to compare the trained model to some holdout test data. But since this is a toy example I used the training data</em>.</p>
<h2>Apply The Learner To A New Data Point</h2>
<p>Now that we have trained our model, we can predict the class any new observation, $y_{test}$. Let us do that now!</p>
<div class="highlight"><pre><span></span><span class="c1"># Create a new observation with the value of the first independent variable, &#39;test_1&#39;, as .4 </span>
<span class="c1"># and the second independent variable, test_1&#39;, as .6 </span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span><span class="o">.</span><span class="mi">6</span><span class="p">]])</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Apply the learner to the new, unclassified observation.</span>
<span class="n">trained_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>array([&#39;loss&#39;], dtype=object)
</pre></div>


<p>Huzzah! We can see that the learner has predicted that the new observation's class is <code>loss</code>.</p>
<p>We can even look at the probabilities the learner assigned to each class:</p>
<div class="highlight"><pre><span></span><span class="n">trained_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>array([[ 0.66666667,  0.33333333]])
</pre></div>


<p>According to this result, the model predicted that the observation was <code>loss</code> with a ~67% probability and <code>win</code> with a ~33% probability. Because the observation had a greater probability of being <code>loss</code>, it predicted that class for the observation.</p>
<h2>Notes</h2>
<ul>
<li>The choice of K has major affects on the classifer created.</li>
<li>The greater the K, more linear (high bias and low variance) the decision boundary.</li>
<li>There are a variety of ways to measure distance, two popular being simple euclidean distance and cosine similarity.</li>
</ul>
</div>
    <aside>
    <div class="bug-reporting__panel">
        <h3>Find an error or bug?</h3>
        <p>Everything on this site is available on GitHub. Head to <a href='https://github.com/chrisalbon/notes_on_data_science_machine_learning_and_artificial_intelligence/issues/new'>and submit a suggested change</a>. You can also message me directly on <a href='https://twitter.com/chrisalbon'>Twitter</a>.</p>
    </div>
    </aside>
</section>

    </div>
    <!-- start of footer section -->
    <footer class="footer">
        <div class="container">
            <p class="text-muted">
                <center>This project contains 486 pages and is available on <a href="https://github.com/chrisalbon/notes_on_data_science_machine_learning_and_artificial_intelligence">GitHub</a>.
                <br/>
                Copyright &copy; Chris Albon,
                    <time datetime="2017">2017</time>.
                </center>
            </p>
        </div>
    </footer>

    <!-- This jQuery line finds any span that contains code highlighting classes and then selects the parent <pre> tag and adds a border. This is done as a workaround to visually distinguish the code inputs and outputs -->
    <script>
        $( ".hll, .n, .c, .err, .k, .o, .cm, .cp, .c1, .cs, .gd, .ge, .gr, .gh, .gi, .go, .gp, .gs, .gu, .gt, .kc, .kd, .kn, .kp, .kr, .kt, .m, .s, .na, .nb, .nc, .no, .nd, .ni, .ne, .nf, .nl, .nn, .nt, .nv, .ow, .w, .mf, .mh, .mi, .mo, .sb, .sc, .sd, .s2, .se, .sh, .si, .sx, .sr, .s1, .ss, .bp, .vc, .vg, .vi, .il" ).parent( "pre" ).css( "border", "1px solid #DEDEDE" );
    </script>

    <!-- Load Google Analytics -->
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-66582-32', 'auto');
        ga('send', 'pageview');
    </script>
    <!-- End of Google Analytics -->

    <!-- Bootstrap core JavaScript
      ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../theme/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../theme/js/ie10-viewport-bug-workaround.js"></script>
    <!-- Amazon OneLink -->
    <script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=946c0716-c88a-4df0-8944-a058be8c1e86"></script>

</body>

</html>